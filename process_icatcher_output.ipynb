{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66a8dca",
   "metadata": {},
   "source": [
    "# iCatcher annotations --> looking time pipeline\n",
    "\n",
    "This script organizes iCatcher annotations and other subject and trial level data into a format that can feed into the rest of the lab's looking time pipeline. It does this by organizing subject, trial, and look level data in the same format as is output in by Datavyu manual coding. \n",
    "\n",
    "## Inputs: \n",
    "\n",
    "\n",
    "### 1. subject-level data: \n",
    "    - subject ID* \n",
    "    - session number**\n",
    "    - DOB \n",
    "    - gender\n",
    "    - session date \n",
    "    - subject group, if relevant\n",
    "    - any other subject-level variables \n",
    "    \n",
    "    * required\n",
    "    ** default is '1' if not provided \n",
    "    \n",
    "### 2. iCatcher annotation file/s (.npz file per subject, per session)\n",
    "\n",
    "These are the main outputs from running iCatcher. Expects one file per subject, per session, named accordingly. \n",
    "\n",
    "### 3. actual video files \n",
    "\n",
    "   needed to extract frame rates for conversion from frame rates to ms (to get look events onset/offset relative to start of video)\n",
    "    \n",
    "   if this conversion has already been run, .json files with the relevant information should exist in the videos directory. if not, these .json files will be written in the process of obtaining this info \n",
    "   \n",
    "### 4. trial onsets relative to start of video\n",
    "\n",
    "   Note, for experiments that used manual triggers for trials or software that does not output log files with trial timing info, you will still need to create a manual log of trial onsets with respect to the start of the video using visual inspection of recorded videos or handwritten logs. Please see notes below on manual timing info for formatting instructions. \n",
    "\n",
    "   **(4a) trial onsets/offsets relative to start of experiment**\n",
    "\n",
    "   Trial onsets are typically recorded in stimulus presentation software with respect to the start of the experiment. That is, you get an output log file with timestamps for when each trial began (and either trial durations or trial ends). \n",
    "    \n",
    "   In Lookit, which can record _and_ present stimuli, video and experiment onsets are logged, and the log files (.json) can be used to get step (3b) below given only the single log file. \n",
    "\n",
    "   **(4b) experiment onset with respect to start of video**\n",
    "    \n",
    "   Ultimately we need trial onsets with respect to the start of the video, since this is how look events are annotated. If we only have trial onsets/offsets with respect to the start of the experiment, we need one additional number, which is how long after the video onset (in ms) the experiment started. Then we can add this value to the trial times to get trial onsets/offsets with respect to video onset. \n",
    "    \n",
    "   If this number is not recorded automatically (we only know of lookit as a software capable of this), you will need to manually evaluate this through manual \"coding\" and produce a file called `sub-<subjID>_session-<sessionID>_experiment_onset.txt` in your input_files folder. \n",
    "    \n",
    "   E.g., if the experiment starts at video timestamp 423ms for subjectID=SAX_ASDF_03 and sessionID=01, then there should be a file called sub-SAX_ASDF_03_session-1_experiment_onset.txt that ONLY contains the content: `423` \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c6e3e",
   "metadata": {},
   "source": [
    "## Setting the `trial_timing_method` variable \n",
    "\n",
    "this variable defines how trial onsets/durations/offsets are obtained, either with respect to video \n",
    "\n",
    "\n",
    "### 1:  from 'manually-formatted' file \n",
    "\n",
    "this supposes you are either manually writing down experiment onset times, or that you have written your own code to extract this data from a file format not yet supported\n",
    "\n",
    "to use this option, you are expected to have CSVs named `sub-<subjID>_session-<sessionID>_trial_info.txt` in the input_files folder. \n",
    "\n",
    "These files are expected to have the following columns (including header names): \n",
    "    trialNumber: integer, from 1 to _n_ trials; which trial \n",
    "    \n",
    "    onset: integer or float, in ms, with respect to start of experiment OR video (if with respect to start of experiment, `sub-<subjID>_session-<sessionID>_experiment_onset.txt` should contain a non-zero value -- see section below); at what time in ms did the trial start \n",
    "    \n",
    "    offset: follows same rules as onset; at one time in ms did the trial end \n",
    "\n",
    "Therefore, you should have 3 columns and _n_ rows, where _n_ is the number of trials for this subject/session\n",
    "\n",
    "\n",
    "### 2: from lookit logs \n",
    "\n",
    "uses lookit 'parser' (code from Gal to parse lookit .json logs) to obtain both trial onsets/offsets and experiment/video onsets to define trial times with respect to the video, all in one go\n",
    "\n",
    "\n",
    "### _3+: future parsers_\n",
    "\n",
    "_In the future, we can make parsers for other log formats, e.g., jsPsych, PsychoPy, OpenSesame, PsychToolBox, etc. Please inform your lab tech if you have another log format and/or could not easily convert your logs to 'manually-formatted files' on your own_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c958d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_timing_method = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c646",
   "metadata": {},
   "source": [
    "## Setting the `experiment_onset_method` variable\n",
    "\n",
    "this variable defines whether you are reading experiment onset with respect to the video from a file (see 4b above) or by using a Lookit parser \n",
    "\n",
    "### 1: manual  \n",
    "\n",
    "looks for `sub-<subjID>_session-<sessionID>_experiment_onset.txt` to add value in file to all trial times  \n",
    "\n",
    "note: if you use some software besides lookit that outputs this information, you can:\n",
    "    (1) create a secondary script to pull this information from whatever log files you have and write the files `sub-<subjID>_session-<sessionID>_experiment_onset.txt`; that is, set to manual (`experiment_onset_method = 1`) even if not literally manually obtained \n",
    "    (2) ask your lab tech to build you a parser for your file type \n",
    "    \n",
    "    Note, if your trial times are read from a file but are already defined with respect to the video, you still should create these expected files, with the value written in each file set to 0 to prevent crashing \n",
    "    \n",
    "### 2: lookit \n",
    "\n",
    "uses lookit 'parser' (code from Gal to parse lookit .json logs) to obtain both trial onsets/offsets and experiment/video onsets to define trial times with respect to the video, all in one go\n",
    "\n",
    "### _3+: future parsers_\n",
    "\n",
    "_In the future, we can make parsers for other log formats, e.g., jsPsych, PsychoPy, OpenSesame, PsychToolBox, etc. Please inform your lab tech if you have another log format and/or could not easily convert your logs to 'manually-formatted files' on your own_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe165ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_onset_method = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67b8c3",
   "metadata": {},
   "source": [
    "## Setting the `subject_info_method` variable\n",
    "\n",
    "this variable defines whether you are reading subject-level variables from an isolated CSV or from some other parser \n",
    "\n",
    "\n",
    "### 1: manual  \n",
    "\n",
    "looks for `sub-<subjID>_session-<sessionID>_subject_info.csv` \n",
    "    \n",
    "Expects the following information, read as a CSV with headers (i.e., the CSV should have 2 rows: row 1 is column names, row 2 is info; as many columns as subject-level variables you want to include):\n",
    "\n",
    "    - subject_ID* (as type: string)\n",
    "    - session_number** (as type: integer)\n",
    "    - DOB -- (mm/dd/yyyy)\n",
    "    - gender (as type: string)\n",
    "    - session_date (mm/dd/yyyy)\n",
    "    - subject_group, if relevant (as type: string)\n",
    "    \n",
    "    * required\n",
    "    ** default is '1' if not provided \n",
    "   \n",
    "    \n",
    "### 2: lookit \n",
    "\n",
    "uses lookit 'parser' (code from Gal to parse lookit .json logs) to obtain subject, session data \n",
    "\n",
    "\n",
    "### _3+: future parsers_\n",
    "\n",
    "_In the future, we can make parsers for other log formats, e.g., jsPsych, PsychoPy, OpenSesame, PsychToolBox, etc. Please inform your lab tech if you have another log format and/or could not easily convert your logs to 'manually-formatted files' on your own_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7452e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_info_method = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777868b2",
   "metadata": {},
   "source": [
    "next steps: \n",
    "\n",
    "\n",
    "- check over lookit reading stuff (using gal's example)\n",
    "\n",
    "- read in new CSV w/ subject level info \n",
    "- edit write to CSV func \n",
    "- check over main func \n",
    "\n",
    "- see what other parsers he has (trial info)\n",
    "- build in parser flexibility\n",
    "\n",
    "- reorganize/clean up/document "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de625cc1",
   "metadata": {},
   "source": [
    "## import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c81917f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helperfuncs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9m/tcr8_jc91v313_963m7j9bpw0000gn/T/ipykernel_7558/103990616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_framerates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_frame_information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_framerates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrite_to_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperfuncs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookit_json_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_lookit_trial_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helperfuncs'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from helperfuncs.video_framerates import get_frame_information\n",
    "from helperfuncs.video_framerates import write_to_json\n",
    "from helperfuncs.lookit_json_parser import get_lookit_trial_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22552a05",
   "metadata": {},
   "source": [
    "## Set relevant paths  -- todo: fix paths for various input files -> just folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12438875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global directory path variables. make these your folder names under MCS\n",
    "project_dir = '/om3/group/saxelab/LAB_STANDARD_LOOKING_TIME_CODE/looking_time/template_project_dir'\n",
    "data_dir = op.join(project_dir, 'data')\n",
    "\n",
    "# where are icatcher outputs\n",
    "icatcher_outputs_dir = op.join(data_dir, 'icatcher_outputs')\n",
    "\n",
    "# where are trial info files \n",
    "trial_info_dir = op.join(data_dir, 'trial_info')\n",
    "if (trial_timing_method == 2) or (experiment_onset_method == 2): # if lookit used for anything\n",
    "    lookit_trial_info_csv = op.join(trial_info_dir, 'lookit_trial_timing_info.csv')\n",
    "\n",
    "experiment_onsets_dir = op.join(data_dir, 'video_relative_experiment_onsets')\n",
    "\n",
    "# where are subject info files \n",
    "subject_info_dir = op.join(data_dir, 'subject_info')\n",
    "\n",
    "# where are videos \n",
    "videos_dir = op.join(project_dir, 'data/videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53a8e8",
   "metadata": {},
   "source": [
    "### Create all necessary functions\n",
    "\n",
    "#### get all non-hidden files in dir (helper function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa14a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all files except those beginning with '.' i.e., hidden files \n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dd37e",
   "metadata": {},
   "source": [
    "#### convert iCatcher annotated look-events from frame-wise to timing (ms from video onset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdca46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_convert_output(filename, stamps):\n",
    "    \"\"\"\n",
    "    Given an npz file containing icatcher annotated frames and looks,\n",
    "    converts to pandas DataFrame with another column mapping each frame\n",
    "    to its time stamp in the video\n",
    "    \n",
    "    INPUTS: \n",
    "    filename (string): name of tabulated iCatcher output file in format\n",
    "    '[CHILD_ID].npz'\n",
    "    stamps (List[int]): time stamp for each frame, where stamps[i] is the \n",
    "    time stamp at frame i (determined in function get_frame_information(), IMPORTED function)\n",
    "    \n",
    "    OUTPUTS: \n",
    "    rtype: DataFrame\n",
    "    \n",
    "    \"\"\"\n",
    "    npz = np.load(filename)\n",
    "    df = pd.DataFrame([])\n",
    "\n",
    "    lst = npz.files\n",
    "\n",
    "    df['frame'] = range(1, len(npz[lst[0]]) + 1)\n",
    "    df['on_off'] = ['on' if frame > 0 else 'off' for frame in npz[lst[0]]]\n",
    "    \n",
    "    # TO DO: DELETE IF UNUSED \n",
    "    #df['confidence'] = npz[lst[1]]\n",
    "\n",
    "    # convert frames to ms using frame rate\n",
    "    df['time_ms'] = stamps\n",
    "    df['time_ms'] = df['time_ms'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c909412",
   "metadata": {},
   "source": [
    "#### get trial onsets w/r/t video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcb1d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_sets(child_id, session_id, trial_info_file):\n",
    "    \"\"\"\n",
    "    Finds corresponding trial info \n",
    "    and returns a list of [onset, offset] times for each trial in \n",
    "    milliseconds, with respect to video onset\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if trial_timing_method == 1: # trial info obtained from manually-formatted file\n",
    "        \n",
    "        df = pd.read_csv(trial_info_file)\n",
    "        \n",
    "    if trial_timing_method == 2: # trial info obtained from lookit \n",
    "        \n",
    "        if Path(lookit_trial_info_csv).is_file(): # check whether lookit file already parsed\n",
    "            df = pd.read_csv(trial_info_file)\n",
    "            \n",
    "        else: # otherwise, parse and save out relevant info  \n",
    "            df = get_lookit_trial_times(icatcher_outputs_dir)\n",
    "            df.to_csv(lookit_trial_info_csv)\n",
    "            \n",
    "    \n",
    "            # get part of df from current child\n",
    "            df = df[df['child_id'] == child_id] \n",
    "            df = df[df['session_id'] == session_id] \n",
    "            \n",
    "            \n",
    "    if experiment_onset_method == 1: # if NOT lookit for experiment onset info too... \n",
    "    \n",
    "        onset_file = glob.glob(op.join(experiment_onsets_dir, 'sub-{}_session-{}_experiment_onset.txt'.format(child_id, session_id)))[0]\n",
    "    \n",
    "        #get experiment onset \n",
    "        with open(onset_file) as f:\n",
    "            text = f.read()\n",
    "            expt_onset = int(text)\n",
    "            \n",
    "            # add difference to create relative onsets/offsets  \n",
    "            \n",
    "            # note: relative means, trial onsets/offsets relative to the start of video \n",
    "            # also note: here we add under assumption that video starts BEFORE experiment starts \n",
    "            # if your video starts AFTER experiment starts, set as negative value in file \n",
    "            df['relative_onset'] = df['onset'] + expt_onset\n",
    "            df['relative_offset'] = df['offset'] + expt_onset\n",
    "\n",
    "    \n",
    "    \n",
    "    # there's two different file formats -- updated as needed \n",
    "    # WHAT IS THIS ?? ASK GAL, MAYBE REMOVE THIS STEP \n",
    "    \n",
    "    df_sets = df[['relative_onset', 'relative_offset']]\n",
    "    df_sets = df_sets.rename(columns={\"relative_onset\": \"onset\", \"relative_offset\": \"offset\"})\n",
    "\n",
    "    df_sets.dropna(inplace=True)\n",
    "        \n",
    "        \n",
    "    trial_sets = []\n",
    "    for _, trial in df_sets.iterrows():\n",
    "        trial_sets.append([int(trial['onset']), int(trial['offset'])])\n",
    "\n",
    "    def unique(sequence):\n",
    "        seen = set()\n",
    "        return [x for x in sequence if not (tuple(x) in seen or seen.add(tuple(x)))]\n",
    "\n",
    "    \n",
    "    \n",
    "    return unique(trial_sets), df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b548ce",
   "metadata": {},
   "source": [
    "#### Get subject level data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f1476ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_info(child_id, session_id): \n",
    "    \n",
    "    if experiment_onset_method == 1:\n",
    "        subject_info_file = glob.glob(op.join(subject_info_dir, 'sub-{}_session-{}_subject_info.csv'.format(child_id, session_id)))[0]\n",
    "        df = pd.read_csv(subject_info_file)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7894cf4e",
   "metadata": {},
   "source": [
    "#### write a csv with subject, trial, and look level information (datavyu format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(data_filename, child_id, icatcher_data, session, trial_type, stim_type, icatcher):\n",
    "    \"\"\"\n",
    "    checks if output file is in directory. if not, writes new file\n",
    "    containing looking times computed by iCatcher and Datavyu for child\n",
    "    with Lookit ID id. \n",
    "    \n",
    "    child_id (string): unique child ID associated with subject\n",
    "    icatcher_data (List[List[int]]): list of [on times, off times] per trial\n",
    "                calculated form iCatcher\n",
    "    datavyu_data (List[List[int]]): list of [on times, off times] per trial\n",
    "                calculated form iCatcher\n",
    "    session (string): the experiment session the participant was placed in\n",
    "    rtype: None\n",
    "    \"\"\"\n",
    "    # assert(len(icatcher_data) == len(datavyu_data))\n",
    "    num_trials = len(icatcher_data)\n",
    "    id_arr = [child_id] * len(icatcher_data)\n",
    "    data = {\n",
    "        'child': id_arr, # * subject level info\n",
    "        'session': [session] * num_trials, # * subject level info\n",
    "        'trial_num': [i + 1 for i in range(len(icatcher_data))], # * Trials.ordinal\n",
    "        'trial_type': trial_type, # * Trials.x\n",
    "        'stim_type': stim_type, # * Trial level info\n",
    "        'confidence': list(icatcher[(icatcher['on_off'] == 'on') & (icatcher['trial'] != 0)].groupby('trial')[['confidence']].mean().squeeze()), # * no confidence\n",
    "        'iCatcher_on(s)': [trial[0] for trial in icatcher_data], # * don't want this\n",
    "        'iCatcher_off(s)': [trial[1] for trial in icatcher_data] # * don't want this\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    output_file = Path(data_filename)\n",
    "    if not output_file.is_file():\n",
    "        df.to_csv(data_filename)\n",
    "        return\n",
    "    \n",
    "    output_df = pd.read_csv(data_filename, index_col=0)\n",
    "    ids = output_df['child'].unique()\n",
    "\n",
    "    if child_id not in ids:\n",
    "        output_df = output_df.append(df, ignore_index=True)\n",
    "        output_df.to_csv(data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad800a",
   "metadata": {},
   "source": [
    "### main function: run processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1be216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analyze_output(data_filename=\"BBB_output.csv\", session=None):\n",
    "    \"\"\"\n",
    "    Given an iCatcher output directory and Datavyu input and output \n",
    "    files, runs iCatcher over all videos in vid_dir that have not been\n",
    "    already run, computes looking times for all iCatcher outputs, and\n",
    "    compares with Datavyu looking times. \n",
    "    data_filename (string): name of file you want comparison data to be written\n",
    "            to. Must have .csv ending. \n",
    "    session (string): ID of the experiment session. If session is not\n",
    "            specified, looks for videos only within videos_dir, otherwise\n",
    "            searches within [videos_dir]/session[session]\n",
    "    \"\"\"\n",
    "    for filename in listdir_nohidden(icatcher_outputs_dir):\n",
    "        child_id = filename.split('.')[0]\n",
    "        \n",
    "        session_id = 1;\n",
    "        # TO DO: UPDATE \n",
    "        \n",
    "        # determine trial info files \n",
    "        if trial_timing_method == 1:\n",
    "            trial_info_file = glob.glob(op.join(trial_info_dir, 'sub-{}_session-{}_trial_info.csv'.format(child_id, session_id)))[0]\n",
    "        elif trial_timing_method == 2:\n",
    "            trial_info_file = lookit_trial_info_csv\n",
    "                                 \n",
    "\n",
    "        # skip if child data already added\n",
    "        output_file = Path(data_filename)\n",
    "        if output_file.is_file():\n",
    "            output_df = pd.read_csv(data_filename, index_col=0)\n",
    "            ids = output_df['child'].unique()\n",
    "            if child_id in ids: \n",
    "                print(child_id + ' already processed')\n",
    "                continue\n",
    "        \n",
    "        vid_path = videos_dir + '/'\n",
    "        if session:\n",
    "            vid_path += \"session\" + session + '/'\n",
    "        vid_path = vid_path + child_id + \".mp4\"\n",
    "        json_video_data = vid_path + child_id + '.json'\n",
    "\n",
    "        # get timestamp for each frame in the video\n",
    "        print('getting frame information for {}...'.format(vid_path))\n",
    "        timestamps, length = get_frame_information(vid_path, json_video_data)\n",
    "        if not timestamps:\n",
    "            print('video not found for {} in {} folder'.format(child_id, videos_dir))\n",
    "            continue\n",
    "        \n",
    "        # initialize df with time stamps for iCatcher file\n",
    "        icatcher_path = icatcher_outputs_dir + '/' + filename\n",
    "        icatcher = read_convert_output(icatcher_path, timestamps)\n",
    "\n",
    "        # get trial onsets and offsets from input file, match to iCatcher file\n",
    "        trial_sets, df = get_trial_sets(child_id, session_id, trial_info_file)\n",
    "        \n",
    "        # sum on looks and off looks for each trial\n",
    "        icatcher_times = get_on_off_times(icatcher)\n",
    "        # datavyu_times = get_output_times(output_file)\n",
    "\n",
    "        # check whether number of trials from trial info is the same as \n",
    "        if icatcher['trial'].max() != len(df):\n",
    "            print('mismatch in # of trials between icatcher and session info: {} in {} folder'.format(child_id, videos_dir))\n",
    "            continue\n",
    "\n",
    "        write_to_csv(data_filename, child_id, icatcher_times, session, df['fam_or_test'], df['scene'], icatcher)\n",
    "        # return comparison metrics \n",
    "        # icatcher_arr, datavyu_arr = np.array(icatcher_times).flatten(), np.array(datavyu_times).flatten()\n",
    "        #stat, p = pearsonr(icatcher_arr, datavyu_arr)\n",
    "       # print('Datavyu total on-off looks per trial: \\n', datavyu_times)\n",
    "      #  print('iCatcher total on-off looks per trial: \\n', icatcher_times)\n",
    "      #  print('Pearson R coefficient: {} \\np-value: {}'.format(round(stat, 3), round(p, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3642df3",
   "metadata": {},
   "source": [
    "# EXECUTE HERE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "373b0857",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_analyze_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9m/tcr8_jc91v313_963m7j9bpw0000gn/T/ipykernel_7558/2162826539.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_analyze_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_analyze_output' is not defined"
     ]
    }
   ],
   "source": [
    "run_analyze_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
